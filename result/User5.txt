Model: linear-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.43266648054122925, precision: 0.8799999952316284, recall: 0.8627451062202454, f1score: 0.8712871305475794
Model: linear-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.40153783559799194, precision: 0.8999999761581421, recall: 0.8823529481887817, f1score: 0.8910891008007794
Model: linear-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.37695303559303284, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: linear-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.3760421574115753, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: linear-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.35768014192581177, precision: 0.8999999761581421, recall: 0.8823529481887817, f1score: 0.8910891008007794
Model: linear-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4232656955718994, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: linear-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4005286991596222, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: linear-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.45978981256484985, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.34263259172439575, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: linear-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.44618046283721924, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: linear-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.41369202733039856, precision: 0.8571428656578064, recall: 0.8235294222831726, f1score: 0.8400000095605851
Model: linear-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.36657318472862244, precision: 0.8775510191917419, recall: 0.843137264251709, f1score: 0.8600000042796134
Model: linear-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.3248867094516754, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.401161789894104, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.34789058566093445, precision: 0.8199999928474426, recall: 0.8039215803146362, f1score: 0.8118811905728801
Model: linear-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.29269126057624817, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: relu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.31876397132873535, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.5284065008163452, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.39503535628318787, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: relu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5407496690750122, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.3948934078216553, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.49036625027656555, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: relu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.3855925500392914, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.24706721305847168, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4264041781425476, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: relu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5035720467567444, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4428611397743225, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: relu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.58223557472229, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: relu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4775851368904114, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: relu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.4341481626033783, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.526957631111145, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: relu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4191659688949585, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: relu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.41974976658821106, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: relu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.28869009017944336, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.34654542803764343, precision: 0.8799999952316284, recall: 0.8627451062202454, f1score: 0.8712871305475794
Model: relu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.5482581853866577, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.41778722405433655, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: relu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4832010567188263, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: relu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.4968053698539734, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: relu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.46392035484313965, precision: 0.8999999761581421, recall: 0.8823529481887817, f1score: 0.8910891008007794
Model: tanh-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.37520214915275574, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.5980175733566284, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4425544738769531, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.3172872066497803, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.5164431929588318, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: tanh-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.5799511075019836, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.4557412564754486, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: tanh-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.3816134035587311, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4116990566253662, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.5169878005981445, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. accuracy: 0.8235294222831726, loss: 0.5452039241790771, precision: 0.8199999928474426, recall: 0.8039215803146362, f1score: 0.8118811905728801
Model: tanh-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4699547588825226, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.45343199372291565, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.41780227422714233, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.35907670855522156, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4741804599761963, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.5881785750389099, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.38841843605041504, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.43755871057510376, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.5421707034111023, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.43204379081726074, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.5299951434135437, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.3623497188091278, precision: 0.8775510191917419, recall: 0.843137264251709, f1score: 0.8600000042796134
Model: tanh-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.5317608118057251, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: sigmoid-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.2966460883617401, precision: 0.8775510191917419, recall: 0.843137264251709, f1score: 0.8600000042796134
Model: sigmoid-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.41395455598831177, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: sigmoid-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4281783401966095, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.3902159035205841, precision: 0.8571428656578064, recall: 0.8235294222831726, f1score: 0.8400000095605851
Model: sigmoid-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.37404754757881165, precision: 0.8571428656578064, recall: 0.8235294222831726, f1score: 0.8400000095605851
Model: sigmoid-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.38552579283714294, precision: 0.8799999952316284, recall: 0.8627451062202454, f1score: 0.8712871305475794
Model: sigmoid-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.408723920583725, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: sigmoid-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4196700155735016, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: sigmoid-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4008699357509613, precision: 0.8199999928474426, recall: 0.8039215803146362, f1score: 0.8118811905728801
Model: sigmoid-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4118592441082001, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.3707425594329834, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: sigmoid-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4394446611404419, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4572656750679016, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.36416566371917725, precision: 0.8799999952316284, recall: 0.8627451062202454, f1score: 0.8712871305475794
Model: sigmoid-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4282546043395996, precision: 0.8333333134651184, recall: 0.7843137383460999, f1score: 0.8080808055630725
Model: sigmoid-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.4219096302986145, precision: 0.8571428656578064, recall: 0.8235294222831726, f1score: 0.8400000095605851
Model: sigmoid-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.48189103603363037, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4592951834201813, precision: 0.8367347121238708, recall: 0.8039215803146362, f1score: 0.8200000148415565
Model: sigmoid-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4096181094646454, precision: 0.875, recall: 0.8235294222831726, f1score: 0.8484848540676526
Model: sigmoid-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.37631428241729736, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: sigmoid-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.3852198123931885, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: sigmoid-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.44796618819236755, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: sigmoid-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4524044692516327, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.3889656364917755, precision: 0.8199999928474426, recall: 0.8039215803146362, f1score: 0.8118811905728801
Model: leakyRelu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4404922127723694, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.33694690465927124, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4231868088245392, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.36960288882255554, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4415462613105774, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.40744370222091675, precision: 0.8799999952316284, recall: 0.8627451062202454, f1score: 0.8712871305475794
Model: leakyRelu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.6164522171020508, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.31006044149398804, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.47597312927246094, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5659551620483398, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4051145911216736, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.3914988934993744, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.38644668459892273, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4155692756175995, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.4179850220680237, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.39789053797721863, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.434070348739624, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.3838614523410797, precision: 0.8199999928474426, recall: 0.8039215803146362, f1score: 0.8118811905728801
Model: leakyRelu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.3553018867969513, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.6095014214515686, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.3831724226474762, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.4013056755065918, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4581841826438904, precision: 0.8199999928474426, recall: 0.8039215803146362, f1score: 0.8118811905728801
Model: leakyRelu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.5514736771583557, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: linear-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 0.7835473418235779, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: linear-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.225892186164856, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.2334786653518677, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.4686216115951538, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: linear-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.295215368270874, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: linear-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.5659550428390503, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: linear-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.1987868547439575, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: linear-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.70146644115448, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 3.0744197368621826, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: linear-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.916775107383728, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: linear-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.484086275100708, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: linear-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 2.1500086784362793, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.7341132164001465, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: linear-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 0.9835484623908997, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: linear-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.0797516107559204, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: linear-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.4696108102798462, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 2.0606701374053955, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.1391878128051758, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.5913559198379517, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.1255617141723633, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 0.8819482922554016, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: relu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.9572721719741821, precision: 0.8799999952316284, recall: 0.8627451062202454, f1score: 0.8712871305475794
Model: relu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.8880231380462646, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.6289544701576233, precision: 0.8999999761581421, recall: 0.8823529481887817, f1score: 0.8910891008007794
Model: relu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.312171220779419, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.3933167457580566, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: relu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 2.4032201766967773, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.670668601989746, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: relu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.7505053281784058, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: relu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 2.257666826248169, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.728206992149353, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: relu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.730156660079956, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 1.8588727712631226, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: relu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 1.8556206226348877, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: relu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 2.5221102237701416, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: relu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.5175962448120117, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: relu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.8613993525505066, precision: 0.8999999761581421, recall: 0.8823529481887817, f1score: 0.8910891008007794
Model: relu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 0.798033595085144, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: relu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.412717580795288, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: relu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.6758263111114502, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.41549813747406, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.7278366684913635, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 1.5715932846069336, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.135226011276245, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.3349127769470215, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.8448632955551147, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.6353923082351685, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.8772955536842346, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.7824373245239258, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.903795599937439, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 3.385751247406006, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.1188617944717407, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.778465986251831, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 2.351717710494995, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.6783502101898193, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.6873137950897217, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.325343370437622, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.687451958656311, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.838231325149536, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 1.4046684503555298, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.488663911819458, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.09610915184021, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.9044958353042603, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 2.172999620437622, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: sigmoid-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 2.0112717151641846, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: sigmoid-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.0400491952896118, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: sigmoid-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.7420851588249207, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: sigmoid-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.3171451091766357, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.1601217985153198, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: sigmoid-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.2870097160339355, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.583388328552246, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: sigmoid-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.5467718839645386, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: sigmoid-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.5528818368911743, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: sigmoid-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.388913869857788, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: sigmoid-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 3.246758222579956, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: sigmoid-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.5659183263778687, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: sigmoid-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 1.7735490798950195, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: sigmoid-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 2.2979094982147217, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: sigmoid-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 1.6155601739883423, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: sigmoid-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.036505937576294, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: sigmoid-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 1.8419281244277954, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: sigmoid-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 1.8181744813919067, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: sigmoid-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 2.351532220840454, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: sigmoid-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.2960342168807983, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: sigmoid-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.5446670055389404, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: sigmoid-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.9514544010162354, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: sigmoid-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.101900339126587, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.4409784078598022, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.4304068088531494, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: leakyRelu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.049627661705017, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.3082412481307983, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.3655072450637817, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.4367895126342773, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.9900084733963013, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: leakyRelu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.9650012254714966, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.1512839794158936, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.830195665359497, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: leakyRelu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.7442567348480225, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.058340072631836, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.2698935270309448, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.89469575881958, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 2.402963638305664, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.5153069496154785, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.403630495071411, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.19386887550354, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 2.124884605407715, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: leakyRelu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.4432790279388428, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.2461681365966797, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: leakyRelu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.229969024658203, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.873176634311676, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.2915359735488892, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.58825945854187, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
REF: Model: tanh-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.5169878005981445, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.843137264251709, loss: 0.9002916216850281, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.843137264251709, loss: 1.086748719215393, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.8627451062202454, loss: 1.2736517190933228, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 1.4756876230239868, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.843137264251709, loss: 2.108046054840088, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.8039215803146362, loss: 4.450926303863525, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.7843137383460999, loss: 0.8747734427452087, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.7843137383460999, loss: 1.1512744426727295, precision: 0.7799999713897705, recall: 0.7647058963775635, f1score: 0.7722772208513804
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.7186951637268066, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.0610147714614868, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 1.2336543798446655, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 1.489412784576416, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.9892352819442749, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.3403096199035645, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 1.4166488647460938, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.026975393295288, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 1.0380831956863403, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8823529481887817, loss: 0.9287042021751404, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.843137264251709, loss: 0.948688268661499, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 1.0339983701705933, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.8880655765533447, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 1.4372049570083618, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.6286703944206238, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 0.7971971035003662, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.843137264251709, loss: 0.7651156187057495, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.843137264251709, loss: 0.46474725008010864, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.843137264251709, loss: 0.43089011311531067, precision: 0.8775510191917419, recall: 0.843137264251709, f1score: 0.8600000042796134
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.7298375964164734, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.7399455308914185, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.8627451062202454, loss: 0.598785936832428, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.7843137383460999, loss: 0.8425285220146179, precision: 0.800000011920929, recall: 0.7843137383460999, f1score: 0.79207922031968
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.7843137383460999, loss: 0.8670942187309265, precision: 0.800000011920929, recall: 0.7843137383460999, f1score: 0.79207922031968
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.6342400908470154, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.7671051621437073, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.4240790605545044, precision: 0.875, recall: 0.8235294222831726, f1score: 0.8484848540676526
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.9386954307556152, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.760967493057251, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.6152946949005127, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.3924705386161804, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.5311712622642517, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.9019607901573181, loss: 0.29490920901298523, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.843137264251709, loss: 0.4481513798236847, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 0.4697519838809967, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.8039215803146362, loss: 0.5095829963684082, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.7852627635002136, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 0.6311819553375244, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.843137264251709, loss: 0.5627575516700745, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.563973069190979, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.8627451062202454, loss: 0.4177592694759369, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.43559837341308594, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.5708192586898804, precision: 0.8297872543334961, recall: 0.7647058963775635, f1score: 0.7959183842775376
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.7450980544090271, loss: 0.5312379002571106, precision: 0.7708333134651184, recall: 0.7254902124404907, f1score: 0.7474747468179466
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.7647058963775635, loss: 0.47619104385375977, precision: 0.8085106611251831, recall: 0.7450980544090271, f1score: 0.7755102228120385
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.843137264251709, loss: 0.5192512273788452, precision: 0.8837209343910217, recall: 0.7450980544090271, f1score: 0.8085106489829965
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.7843137383460999, loss: 0.6731185913085938, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.7647058963775635, loss: 0.4864096939563751, precision: 0.8125, recall: 0.7647058963775635, f1score: 0.7878787953225267
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.4566051959991455, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4143901765346527, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.5074118971824646, precision: 0.8297872543334961, recall: 0.7647058963775635, f1score: 0.7959183842775376
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.38681602478027344, precision: 0.875, recall: 0.8235294222831726, f1score: 0.8484848540676526
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4113296866416931, precision: 0.8541666865348816, recall: 0.8039215803146362, f1score: 0.8282828438271066
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.48622605204582214, precision: 0.8260869383811951, recall: 0.7450980544090271, f1score: 0.7835051548798994
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.6376128196716309, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.3725122809410095, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 0.36142227053642273, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.843137264251709, loss: 0.35128021240234375, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.45435455441474915, precision: 0.8775510191917419, recall: 0.843137264251709, f1score: 0.8600000042796134
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 0.32867327332496643, precision: 0.8367347121238708, recall: 0.8039215803146362, f1score: 0.8200000148415565
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 0.3790658712387085, precision: 0.8913043737411499, recall: 0.8039215803146362, f1score: 0.8453608428599515
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 0.49225327372550964, precision: 0.8297872543334961, recall: 0.7647058963775635, f1score: 0.7959183842775376
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.7843137383460999, loss: 0.5511066317558289, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.8039215803146362, loss: 0.42435890436172485, precision: 0.8367347121238708, recall: 0.8039215803146362, f1score: 0.8200000148415565
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8039215803146362, loss: 0.5650240182876587, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8039215803146362, loss: 0.3190271854400635, precision: 0.8199999928474426, recall: 0.8039215803146362, f1score: 0.8118811905728801
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.4191933572292328, precision: 0.8571428656578064, recall: 0.8235294222831726, f1score: 0.8400000095605851
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8627451062202454, loss: 0.4849109351634979, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.6643369793891907, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.4556911587715149, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8627451062202454, loss: 0.40964996814727783, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8627451062202454, loss: 0.4717763364315033, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.3834652006626129, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.34476518630981445, precision: 0.8799999952316284, recall: 0.8627451062202454, f1score: 0.8712871305475794
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.612923800945282, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.6594564914703369, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.44479331374168396, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.6592953205108643, precision: 0.800000011920929, recall: 0.7843137383460999, f1score: 0.79207922031968
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.5748006701469421, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.843137264251709, loss: 0.5841183066368103, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.8823529481887817, loss: 0.45845741033554077, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 0.3955211341381073, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.843137264251709, loss: 0.5940784215927124, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.470729261636734, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.4069593846797943, precision: 0.8775510191917419, recall: 0.843137264251709, f1score: 0.8600000042796134
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.8823529481887817, loss: 0.35753247141838074, precision: 0.8999999761581421, recall: 0.8823529481887817, f1score: 0.8910891008007794
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.8039215803146362, loss: 0.6210407614707947, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.6470588445663452, loss: 0.7719417810440063, precision: 0.75, recall: 0.5882353186607361, f1score: 0.6593406747582595
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.6470588445663452, loss: 0.9549453854560852, precision: 0.7037037014961243, recall: 0.37254902720451355, f1score: 0.48717949314582976
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.686274528503418, loss: 0.8585542440414429, precision: 0.8399999737739563, recall: 0.4117647111415863, f1score: 0.5526315780083061
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.6078431606292725, loss: 0.8909544944763184, precision: 0.6857143044471741, recall: 0.47058823704719543, f1score: 0.5581395423222129
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.529411792755127, loss: 0.935306191444397, precision: 0.692307710647583, recall: 0.3529411852359772, f1score: 0.46753247940514175
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.6470588445663452, loss: 0.8674174547195435, precision: 0.7692307829856873, recall: 0.3921568691730499, f1score: 0.5194805282568485
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.6078431606292725, loss: 0.8307355046272278, precision: 0.6585366129875183, recall: 0.529411792755127, f1score: 0.58695654994993
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.6274510025978088, loss: 0.7853091359138489, precision: 0.7647058963775635, recall: 0.5098039507865906, f1score: 0.6117647314071653
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.569787859916687, precision: 0.8666666746139526, recall: 0.7647058963775635, f1score: 0.8125000114087015
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 0.6178269982337952, precision: 0.7659574747085571, recall: 0.7058823704719543, f1score: 0.7346938998810404
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.7770180702209473, precision: 0.8275862336158752, recall: 0.47058823704719543, f1score: 0.6000000084470957
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.7973155379295349, precision: 0.800000011920929, recall: 0.5490196347236633, f1score: 0.6511628135531059
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.7752589583396912, precision: 0.8285714387893677, recall: 0.5686274766921997, f1score: 0.6744186261204398
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.8808509707450867, precision: 0.7586206793785095, recall: 0.4313725531101227, f1score: 0.550000000623986
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 0.5296374559402466, precision: 0.8260869383811951, recall: 0.7450980544090271, f1score: 0.7835051548798994
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.7650323510169983, precision: 0.8611111044883728, recall: 0.6078431606292725, f1score: 0.7126436919576344
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.8039215803146362, loss: 0.49306902289390564, precision: 0.9069767594337463, recall: 0.7647058963775635, f1score: 0.8297872486806337
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.8039215803146362, loss: 0.509547233581543, precision: 0.8604651093482971, recall: 0.7254902124404907, f1score: 0.7872340492853592
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.7254902124404907, loss: 0.6547752618789673, precision: 0.7948718070983887, recall: 0.6078431606292725, f1score: 0.6888889084921942
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.7843137383460999, loss: 0.6910263299942017, precision: 0.8292682766914368, recall: 0.6666666865348816, f1score: 0.739130440641666
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.7647058963775635, loss: 0.7409747242927551, precision: 0.8421052694320679, recall: 0.6274510025978088, f1score: 0.7191011404663064
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.7254902124404907, loss: 0.7778308987617493, precision: 0.8787878751754761, recall: 0.5686274766921997, f1score: 0.6904762083170362
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.7450980544090271, loss: 0.6410008072853088, precision: 0.7659574747085571, recall: 0.7058823704719543, f1score: 0.7346938998810404
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.7647058963775635, loss: 0.6927453875541687, precision: 0.7777777910232544, recall: 0.686274528503418, f1score: 0.7291666830424219