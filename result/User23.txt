Model: linear-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 1.1100772619247437, precision: 0.7400000095367432, recall: 0.7254902124404907, f1score: 0.7326732803449807
Model: linear-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.8342769742012024, precision: 0.8163265585899353, recall: 0.7843137383460999, f1score: 0.800000020122528
Model: linear-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 0.6699931025505066, precision: 0.7755101919174194, recall: 0.7450980544090271, f1score: 0.7600000020623204
Model: linear-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.1336164474487305, precision: 0.6938775777816772, recall: 0.6666666865348816, f1score: 0.6800000231862068
Model: linear-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.1600170135498047, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: linear-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.9051769971847534, precision: 0.6875, recall: 0.6470588445663452, f1score: 0.6666666778322748
Model: linear-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.6648897528648376, precision: 0.7551020383834839, recall: 0.7254902124404907, f1score: 0.7400000073432921
Model: linear-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.9930819272994995, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: linear-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.9828492999076843, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: linear-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.7149276733398438, precision: 0.717391312122345, recall: 0.6470588445663452, f1score: 0.6804123862616528
Model: linear-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.8077889084815979, precision: 0.7555555701255798, recall: 0.6666666865348816, f1score: 0.708333350950852
Model: linear-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.6500537395477295, precision: 0.7708333134651184, recall: 0.7254902124404907, f1score: 0.7474747468179466
Model: linear-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.8751677870750427, precision: 0.7346938848495483, recall: 0.7058823704719543, f1score: 0.7200000126242637
Model: linear-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.7371624112129211, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: linear-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.6258435249328613, precision: 0.7755101919174194, recall: 0.7450980544090271, f1score: 0.7600000020623204
Model: linear-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.9850469827651978, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: relu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.0991826057434082, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: relu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 1.6113144159317017, precision: 0.6800000071525574, recall: 0.6666666865348816, f1score: 0.6732673403702814
Model: relu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 0.8039302229881287, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: relu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 1.417837381362915, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: relu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.3219503164291382, precision: 0.7400000095367432, recall: 0.7254902124404907, f1score: 0.7326732803449807
Model: relu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 1.3617171049118042, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: relu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6470588445663452, loss: 1.3786022663116455, precision: 0.6470588445663452, recall: 0.6470588445663452, f1score: 0.6470588445663452
Model: relu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.0972408056259155, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: relu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6274510025978088, loss: 1.7489162683486938, precision: 0.6399999856948853, recall: 0.6274510025978088, f1score: 0.6336633706487818
Model: relu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 1.7024800777435303, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: relu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.7804296016693115, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: relu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 1.2045446634292603, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: relu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.036189079284668, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: relu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.3936398029327393, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: relu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.9915299415588379, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: relu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.1870449781417847, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: relu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.3687708377838135, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: relu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6078431606292725, loss: 0.9653938412666321, precision: 0.6326530575752258, recall: 0.6078431606292725, f1score: 0.6200000104069707
Model: relu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 0.9819392561912537, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: relu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6470588445663452, loss: 1.555208444595337, precision: 0.6470588445663452, recall: 0.6470588445663452, f1score: 0.6470588445663452
Model: relu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.5207741260528564, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: relu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.5882353186607361, loss: 1.6519547700881958, precision: 0.5882353186607361, recall: 0.5882353186607361, f1score: 0.5882353186607361
Model: relu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.0004945993423462, precision: 0.7346938848495483, recall: 0.7058823704719543, f1score: 0.7200000126242637
Model: relu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6470588445663452, loss: 1.4621896743774414, precision: 0.6470588445663452, recall: 0.6470588445663452, f1score: 0.6470588445663452
Model: tanh-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.9258418083190918, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.0360205173492432, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: tanh-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.6839372515678406, precision: 0.7599999904632568, recall: 0.7450980544090271, f1score: 0.7524752505981807
Model: tanh-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 1.0716980695724487, precision: 0.7599999904632568, recall: 0.7450980544090271, f1score: 0.7524752505981807
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.3483446836471558, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: tanh-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.3399583101272583, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: tanh-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.157076120376587, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: tanh-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.7831456661224365, precision: 0.6938775777816772, recall: 0.6666666865348816, f1score: 0.6800000231862068
Model: tanh-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.193097472190857, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: tanh-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.3148539066314697, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: tanh-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.1993436813354492, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.1115198135375977, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: tanh-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.7220251560211182, precision: 0.7291666865348816, recall: 0.686274528503418, f1score: 0.7070707263368549
Model: tanh-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6274510025978088, loss: 1.3181145191192627, precision: 0.6530612111091614, recall: 0.6274510025978088, f1score: 0.640000005125999
Model: tanh-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6274510025978088, loss: 0.925325870513916, precision: 0.6808510422706604, recall: 0.6274510025978088, f1score: 0.6530612265999138
Model: tanh-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 0.9236643314361572, precision: 0.6734693646430969, recall: 0.6470588445663452, f1score: 0.6599999998450272
Model: tanh-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.0286805629730225, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: tanh-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.7785418629646301, precision: 0.7234042286872864, recall: 0.6666666865348816, f1score: 0.6938775495309119
Model: tanh-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.7980731129646301, precision: 0.7446808218955994, recall: 0.686274528503418, f1score: 0.7142857109964109
Model: tanh-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.183851957321167, precision: 0.6800000071525574, recall: 0.6666666865348816, f1score: 0.6732673403702814
Model: tanh-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 1.289941668510437, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: tanh-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.976961612701416, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: tanh-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.6497882008552551, precision: 0.7659574747085571, recall: 0.7058823704719543, f1score: 0.7346938998810404
Model: tanh-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.0828057527542114, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: sigmoid-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.8041511178016663, precision: 0.739130437374115, recall: 0.6666666865348816, f1score: 0.7010309399853021
Model: sigmoid-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.8941511511802673, precision: 0.739130437374115, recall: 0.6666666865348816, f1score: 0.7010309399853021
Model: sigmoid-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6470588445663452, loss: 0.9390495419502258, precision: 0.7209302186965942, recall: 0.6078431606292725, f1score: 0.6595744760449838
Model: sigmoid-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.8200141787528992, precision: 0.7142857313156128, recall: 0.686274528503418, f1score: 0.7000000179052353
Model: sigmoid-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.8225566148757935, precision: 0.7727272510528564, recall: 0.6666666865348816, f1score: 0.715789475837242
Model: sigmoid-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6274510025978088, loss: 1.0004836320877075, precision: 0.6530612111091614, recall: 0.6274510025978088, f1score: 0.640000005125999
Model: sigmoid-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 0.8236294388771057, precision: 0.7346938848495483, recall: 0.7058823704719543, f1score: 0.7200000126242637
Model: sigmoid-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.6988392472267151, precision: 0.7560975551605225, recall: 0.6078431606292725, f1score: 0.6739130555343985
Model: sigmoid-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.8649742007255554, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: sigmoid-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.8749517798423767, precision: 0.7272727489471436, recall: 0.6274510025978088, f1score: 0.673684232624614
Model: sigmoid-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6470588445663452, loss: 0.9457385540008545, precision: 0.6666666865348816, recall: 0.6274510025978088, f1score: 0.646464667591729
Model: sigmoid-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.8470770120620728, precision: 0.7083333134651184, recall: 0.6666666865348816, f1score: 0.6868686880728205
Model: sigmoid-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 0.955069899559021, precision: 0.7209302186965942, recall: 0.6078431606292725, f1score: 0.6595744760449838
Model: sigmoid-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.8294988870620728, precision: 0.6888889074325562, recall: 0.6078431606292725, f1score: 0.6458333546761423
Model: sigmoid-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6274510025978088, loss: 0.9733184576034546, precision: 0.6829268336296082, recall: 0.5490196347236633, f1score: 0.608695670427131
Model: sigmoid-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.5882353186607361, loss: 0.9322598576545715, precision: 0.692307710647583, recall: 0.529411792755127, f1score: 0.600000024901496
Model: sigmoid-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6078431606292725, loss: 1.0700267553329468, precision: 0.6521739363670349, recall: 0.5882353186607361, f1score: 0.6185567250907047
Model: sigmoid-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.5882353186607361, loss: 0.9649053812026978, precision: 0.692307710647583, recall: 0.529411792755127, f1score: 0.600000024901496
Model: sigmoid-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6274510025978088, loss: 0.9438948631286621, precision: 0.7179487347602844, recall: 0.5490196347236633, f1score: 0.6222222457991705
Model: sigmoid-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.744769811630249, precision: 0.7446808218955994, recall: 0.686274528503418, f1score: 0.7142857109964109
Model: sigmoid-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.9337400794029236, precision: 0.7142857313156128, recall: 0.686274528503418, f1score: 0.7000000179052353
Model: sigmoid-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.8821390271186829, precision: 0.7291666865348816, recall: 0.686274528503418, f1score: 0.7070707263368549
Model: sigmoid-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6470588445663452, loss: 0.9061758518218994, precision: 0.75, recall: 0.6470588445663452, f1score: 0.6947368542309281
Model: sigmoid-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.845187246799469, precision: 0.7083333134651184, recall: 0.6666666865348816, f1score: 0.6868686880728205
Model: leakyRelu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6470588445663452, loss: 1.2428537607192993, precision: 0.6470588445663452, recall: 0.6470588445663452, f1score: 0.6470588445663452
Model: leakyRelu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.0637305974960327, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: leakyRelu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.7023789882659912, precision: 0.75, recall: 0.7058823704719543, f1score: 0.7272727365774008
Model: leakyRelu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.0845441818237305, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: leakyRelu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 1.5338808298110962, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: leakyRelu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.1397459506988525, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: leakyRelu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.3316818475723267, precision: 0.6938775777816772, recall: 0.6666666865348816, f1score: 0.6800000231862068
Model: leakyRelu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 0.7805712819099426, precision: 0.7083333134651184, recall: 0.6666666865348816, f1score: 0.6868686880728205
Model: leakyRelu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.229792594909668, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: leakyRelu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.9184905886650085, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: leakyRelu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.011284589767456, precision: 0.7400000095367432, recall: 0.7254902124404907, f1score: 0.7326732803449807
Model: leakyRelu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.9947237372398376, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: leakyRelu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 0.6660014986991882, precision: 0.7599999904632568, recall: 0.7450980544090271, f1score: 0.7524752505981807
Model: leakyRelu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.3064419031143188, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: leakyRelu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.8592228889465332, precision: 0.7291666865348816, recall: 0.686274528503418, f1score: 0.7070707263368549
Model: leakyRelu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.9952820539474487, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: leakyRelu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.8644492030143738, precision: 0.7346938848495483, recall: 0.7058823704719543, f1score: 0.7200000126242637
Model: leakyRelu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 0.6659134030342102, precision: 0.782608687877655, recall: 0.7058823704719543, f1score: 0.7422680474326008
Model: leakyRelu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.8126178979873657, precision: 0.7142857313156128, recall: 0.686274528503418, f1score: 0.7000000179052353
Model: leakyRelu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 1.3868097066879272, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: leakyRelu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.0341095924377441, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: leakyRelu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.0889804363250732, precision: 0.7400000095367432, recall: 0.7254902124404907, f1score: 0.7326732803449807
Model: leakyRelu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.8109327554702759, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: leakyRelu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.2796804904937744, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: linear-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 4.916867256164551, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: linear-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.9677300453186035, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 2.5423266887664795, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: linear-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 3.4902472496032715, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: linear-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 3.353353977203369, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: linear-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 2.361440896987915, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: linear-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.6357451677322388, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: linear-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 2.2756853103637695, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: linear-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 3.7678754329681396, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: linear-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 1.670750379562378, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: linear-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.5735050439834595, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: linear-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 3.3385980129241943, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: linear-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 3.181076765060425, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.5623250007629395, precision: 0.8775510191917419, recall: 0.843137264251709, f1score: 0.8600000042796134
Model: linear-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.8876073360443115, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: linear-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 3.313030242919922, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 5.336071968078613, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: relu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 2.639308214187622, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: relu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 3.1858069896698, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: relu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 5.14752197265625, precision: 0.7799999713897705, recall: 0.7647058963775635, f1score: 0.7722772208513804
Model: relu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 3.3835480213165283, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: relu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 3.7872345447540283, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: relu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 2.977071762084961, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: relu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 2.2766852378845215, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: relu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 4.448301315307617, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: relu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 4.08668851852417, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: relu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 4.3804030418396, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: relu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 3.313633918762207, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: relu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 2.9722394943237305, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: relu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 4.278065204620361, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: relu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 3.4934585094451904, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: relu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.6470588445663452, loss: 4.152732849121094, precision: 0.6470588445663452, recall: 0.6470588445663452, f1score: 0.6470588445663452
Model: relu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 2.4751360416412354, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: relu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.686274528503418, loss: 2.830827236175537, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: relu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 3.067154884338379, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: relu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 3.1608121395111084, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: relu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 4.541843414306641, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: relu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 2.485618829727173, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: relu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 2.594972610473633, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: relu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 3.7051076889038086, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 3.2147021293640137, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 1.7351906299591064, precision: 0.800000011920929, recall: 0.7843137383460999, f1score: 0.79207922031968
Model: tanh-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 2.400441884994507, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 2.721837043762207, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 3.888169288635254, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 4.621946811676025, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: tanh-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 2.8151443004608154, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 2.776503562927246, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 3.813383102416992, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 2.8417935371398926, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: tanh-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 4.162318706512451, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: tanh-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 2.8464953899383545, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 2.3161280155181885, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 3.5317890644073486, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: tanh-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 2.843651294708252, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: tanh-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 4.342763900756836, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 2.8169806003570557, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: tanh-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 2.3284990787506104, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 4.442337512969971, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.9973267316818237, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 3.3857147693634033, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: tanh-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 2.848088026046753, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: tanh-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 2.1545701026916504, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 2.507495880126953, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: sigmoid-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 3.998122453689575, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: sigmoid-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.7235078811645508, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: sigmoid-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 1.5637751817703247, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: sigmoid-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 3.3526031970977783, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: sigmoid-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.6666666865348816, loss: 3.7179296016693115, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: sigmoid-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 4.080681800842285, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: sigmoid-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 3.12526535987854, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: sigmoid-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 2.760266065597534, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: sigmoid-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.2082691192626953, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 1.9846508502960205, precision: 0.7599999904632568, recall: 0.7450980544090271, f1score: 0.7524752505981807
Model: sigmoid-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 4.327075004577637, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: sigmoid-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.686274528503418, loss: 2.833418369293213, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: sigmoid-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 2.0223968029022217, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: sigmoid-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 3.815826416015625, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: sigmoid-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 2.0027246475219727, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: sigmoid-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 4.430160999298096, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: sigmoid-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 2.2226402759552, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: sigmoid-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 2.5203752517700195, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: sigmoid-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 2.766942024230957, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: sigmoid-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.572620153427124, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: sigmoid-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 3.343554973602295, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: sigmoid-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 2.1969122886657715, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: sigmoid-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 2.280866861343384, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: sigmoid-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 3.439746379852295, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 3.526081085205078, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: leakyRelu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.4716410636901855, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.119481325149536, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.8153235912323, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 3.0468711853027344, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: leakyRelu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 4.706057548522949, precision: 0.7599999904632568, recall: 0.7450980544090271, f1score: 0.7524752505981807
Model: leakyRelu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 2.5958166122436523, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: leakyRelu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 1.8632283210754395, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: leakyRelu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 3.997116804122925, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: leakyRelu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7254902124404907, loss: 3.1525371074676514, precision: 0.7346938848495483, recall: 0.7058823704719543, f1score: 0.7200000126242637
Model: leakyRelu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 3.958082914352417, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: leakyRelu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 2.1889922618865967, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: leakyRelu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 2.4452688694000244, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: leakyRelu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.6666666865348816, loss: 3.3012187480926514, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: leakyRelu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 2.3056511878967285, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: leakyRelu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7058823704719543, loss: 3.86452317237854, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: leakyRelu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 3.1258885860443115, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: leakyRelu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7450980544090271, loss: 2.6677684783935547, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: leakyRelu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7647058963775635, loss: 3.640859603881836, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: leakyRelu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.7284581661224365, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 4.034899711608887, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: leakyRelu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.0595903396606445, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8039215803146362, loss: 2.0373685359954834, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: leakyRelu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.7843137383460999, loss: 3.4447383880615234, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
REF: Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.3483446836471558, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.8039215803146362, loss: 1.7017902135849, precision: 0.8199999928474426, recall: 0.8039215803146362, f1score: 0.8118811905728801
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.8039215803146362, loss: 1.634074330329895, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.843137264251709, loss: 0.770525336265564, precision: 0.8333333134651184, recall: 0.7843137383460999, f1score: 0.8080808055630725
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.686274528503418, loss: 2.7015984058380127, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.7058823704719543, loss: 1.8115543127059937, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.8823529481887817, loss: 1.3983935117721558, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.6078431606292725, loss: 3.1956098079681396, precision: 0.6000000238418579, recall: 0.5882353186607361, f1score: 0.5940594301423819
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.6078431606292725, loss: 4.0585618019104, precision: 0.6078431606292725, recall: 0.6078431606292725, f1score: 0.6078431606292725
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 2.2025086879730225, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 2.3931562900543213, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.9680384993553162, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 2.892176866531372, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 2.7713820934295654, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 1.931232213973999, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 3.0548131465911865, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.6274510025978088, loss: 2.695798635482788, precision: 0.6274510025978088, recall: 0.6274510025978088, f1score: 0.6274510025978088
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.7450980544090271, loss: 2.976292610168457, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.7843137383460999, loss: 2.6940605640411377, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8823529481887817, loss: 1.3482396602630615, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.686274528503418, loss: 3.105165958404541, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.7450980544090271, loss: 2.9627153873443604, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 2.132925033569336, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.6666666865348816, loss: 2.4406983852386475, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.686274528503418, loss: 2.192254066467285, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.7058823704719543, loss: 1.6557817459106445, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.7450980544090271, loss: 0.948542594909668, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.7647058963775635, loss: 0.6000196933746338, precision: 0.7857142686843872, recall: 0.6470588445663452, f1score: 0.7096774250610061
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.5490196347236633, loss: 1.7587589025497437, precision: 0.5600000023841858, recall: 0.5490196347236633, f1score: 0.5544554604208826
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.6470588445663452, loss: 1.4854217767715454, precision: 0.6734693646430969, recall: 0.6470588445663452, f1score: 0.6599999998450272
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.7058823704719543, loss: 0.7218854427337646, precision: 0.739130437374115, recall: 0.6666666865348816, f1score: 0.7010309399853021
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.6274510025978088, loss: 1.9543241262435913, precision: 0.6399999856948853, recall: 0.6274510025978088, f1score: 0.6336633706487818
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.6078431606292725, loss: 1.9753851890563965, precision: 0.6200000047683716, recall: 0.6078431606292725, f1score: 0.613861400395582
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.8084717988967896, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 1.222549319267273, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.6517809629440308, precision: 0.7872340679168701, recall: 0.7254902124404907, f1score: 0.7551020613465395
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 1.730802059173584, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.62575364112854, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.7227975726127625, precision: 0.7551020383834839, recall: 0.7254902124404907, f1score: 0.7400000073432921
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.5094529390335083, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 1.6561726331710815, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.7843137383460999, loss: 1.4522186517715454, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.7647058963775635, loss: 1.5956337451934814, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.7254902124404907, loss: 0.7228944301605225, precision: 0.7708333134651184, recall: 0.7254902124404907, f1score: 0.7474747468179466
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.686274528503418, loss: 2.050903558731079, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.7254902124404907, loss: 1.5840659141540527, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.7254902124404907, loss: 0.9759519696235657, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.7254902124404907, loss: 1.783463716506958, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.6078431606292725, loss: 1.8306337594985962, precision: 0.6078431606292725, recall: 0.6078431606292725, f1score: 0.6078431606292725
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.6274510025978088, loss: 0.9967376589775085, precision: 0.6739130616188049, recall: 0.6078431606292725, f1score: 0.6391752788143541
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.5686274766921997, loss: 0.9556460380554199, precision: 0.6666666865348816, recall: 0.5490196347236633, f1score: 0.6021505619062965
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.6078431606292725, loss: 0.9866225123405457, precision: 0.75, recall: 0.1764705926179886, f1score: 0.28571429145849747
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.6274510025978088, loss: 0.9402768015861511, precision: 0.6829268336296082, recall: 0.5490196347236633, f1score: 0.608695670427131
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.6470588445663452, loss: 0.9283502697944641, precision: 0.699999988079071, recall: 0.5490196347236633, f1score: 0.615384627663992
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.6078431606292725, loss: 0.9636591076850891, precision: 0.6785714030265808, recall: 0.37254902720451355, f1score: 0.48101265814189326
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.6470588445663452, loss: 1.1818702220916748, precision: 0.6530612111091614, recall: 0.6274510025978088, f1score: 0.640000005125999
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.6078431606292725, loss: 1.0450725555419922, precision: 0.5952380895614624, recall: 0.4901960790157318, f1score: 0.537634406638071
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.7554293870925903, precision: 0.7446808218955994, recall: 0.686274528503418, f1score: 0.7142857109964109
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 0.8489829897880554, precision: 0.7021276354789734, recall: 0.6470588445663452, f1score: 0.6734693880654129
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.5882353186607361, loss: 0.9201352000236511, precision: 0.7058823704719543, recall: 0.47058823704719543, f1score: 0.5647058892250061
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.6274510025978088, loss: 0.978851318359375, precision: 0.6595744490623474, recall: 0.6078431606292725, f1score: 0.6326530651344148
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.8795411586761475, precision: 0.7560975551605225, recall: 0.6078431606292725, f1score: 0.6739130555343985
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.6274510025978088, loss: 0.9241650700569153, precision: 0.6756756901741028, recall: 0.4901960790157318, f1score: 0.5681818237004816
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 1.459022879600525, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.6666666865348816, loss: 0.89588463306427, precision: 0.7272727489471436, recall: 0.6274510025978088, f1score: 0.673684232624614
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.7058823704719543, loss: 1.025904655456543, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.7254902124404907, loss: 0.8471094965934753, precision: 0.75, recall: 0.7058823704719543, f1score: 0.7272727365774008
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.6078431606292725, loss: 0.9011967778205872, precision: 0.6842105388641357, recall: 0.5098039507865906, f1score: 0.5842696866849472
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.6078431606292725, loss: 0.9585604071617126, precision: 0.625, recall: 0.5882353186607361, f1score: 0.6060606190871489
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.6274510025978088, loss: 0.8413811326026917, precision: 0.6818181872367859, recall: 0.5882353186607361, f1score: 0.6315789638397764
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.6274510025978088, loss: 0.9335398077964783, precision: 0.7105262875556946, recall: 0.529411792755127, f1score: 0.6067415811605865
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.686274528503418, loss: 1.1181986331939697, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.6666666865348816, loss: 0.9306353330612183, precision: 0.7021276354789734, recall: 0.6470588445663452, f1score: 0.6734693880654129
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.6666666865348816, loss: 1.2790697813034058, precision: 0.6666666865348816, recall: 0.6666666865348816, f1score: 0.6666666865348816
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8039215803146362, loss: 0.6352510452270508, precision: 0.8163265585899353, recall: 0.7843137383460999, f1score: 0.800000020122528
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.7058823704719543, loss: 0.7984740138053894, precision: 0.7209302186965942, recall: 0.6078431606292725, f1score: 0.6595744760449838
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.686274528503418, loss: 1.6283961534500122, precision: 0.7142857313156128, recall: 0.686274528503418, f1score: 0.7000000179052353
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.7254902124404907, loss: 0.7811602354049683, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.6666666865348816, loss: 0.817188560962677, precision: 0.738095223903656, recall: 0.6078431606292725, f1score: 0.6666666749364746
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.6470588445663452, loss: 1.6750293970108032, precision: 0.6399999856948853, recall: 0.6274510025978088, f1score: 0.6336633706487818
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.7254902124404907, loss: 1.4948160648345947, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.9561899304389954, precision: 0.7551020383834839, recall: 0.7254902124404907, f1score: 0.7400000073432921
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.7878406047821045, precision: 0.7272727489471436, recall: 0.6274510025978088, f1score: 0.673684232624614
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.3087018728256226, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.6470588445663452, loss: 1.1465661525726318, precision: 0.6734693646430969, recall: 0.6470588445663452, f1score: 0.6599999998450272
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.8622257113456726, precision: 0.760869562625885, recall: 0.686274528503418, f1score: 0.7216494937089515
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 1.6421747207641602, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 1.46290922164917, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.7647058963775635, loss: 1.8458622694015503, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.7058823704719543, loss: 1.452933669090271, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.7450980544090271, loss: 0.6719660758972168, precision: 0.7551020383834839, recall: 0.7254902124404907, f1score: 0.7400000073432921
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.686274528503418, loss: 1.5595251321792603, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.686274528503418, loss: 1.4043806791305542, precision: 0.699999988079071, recall: 0.686274528503418, f1score: 0.6930693106234812
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.7254902124404907, loss: 0.7302721738815308, precision: 0.7142857313156128, recall: 0.686274528503418, f1score: 0.7000000179052353
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.7058823704719543, loss: 1.233339548110962, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.686274528503418, loss: 1.4923882484436035, precision: 0.6800000071525574, recall: 0.6666666865348816, f1score: 0.6732673403702814
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.5490196347236633, loss: 0.9948818683624268, precision: 0.5853658318519592, recall: 0.47058823704719543, f1score: 0.5217391228504012
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.5098039507865906, loss: 0.9871447086334229, precision: 0.6000000238418579, recall: 0.4117647111415863, f1score: 0.48837210462021136
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.5098039507865906, loss: 1.0638771057128906, precision: 0.3333333432674408, recall: 0.05882352963089943, f1score: 0.1000000007636845
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.5490196347236633, loss: 1.0086759328842163, precision: 0.6190476417541504, recall: 0.2549019753932953, f1score: 0.36111112963408226
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.5686274766921997, loss: 0.9827160835266113, precision: 0.6538461446762085, recall: 0.3333333432674408, f1score: 0.44155844818341367
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.6274510025978088, loss: 0.9727787971496582, precision: 0.6428571343421936, recall: 0.1764705926179886, f1score: 0.27692308152921097
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.4901960790157318, loss: 1.024735689163208, precision: 0.5925925970077515, recall: 0.3137255012989044, f1score: 0.4102564208077255
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.4901960790157318, loss: 1.0741760730743408, precision: 0.5833333134651184, recall: 0.27450981736183167, f1score: 0.3733333416938776
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.5490196347236633, loss: 1.0862621068954468, precision: 0.6190476417541504, recall: 0.5098039507865906, f1score: 0.5591398117817651
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.6078431606292725, loss: 0.9032103419303894, precision: 0.6756756901741028, recall: 0.4901960790157318, f1score: 0.5681818237004816
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.5882353186607361, loss: 0.9776135683059692, precision: 0.800000011920929, recall: 0.23529411852359772, f1score: 0.3636363659146403
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.5098039507865906, loss: 0.9909277558326721, precision: 0.6363636255264282, recall: 0.27450981736183167, f1score: 0.3835616549870199
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.529411792755127, loss: 1.0010721683502197, precision: 0.6470588445663452, recall: 0.21568627655506134, f1score: 0.3235294166952371
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.4901960790157318, loss: 1.0367873907089233, precision: 0.5185185074806213, recall: 0.27450981736183167, f1score: 0.35897436782100456
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.4313725531101227, loss: 1.0465264320373535, precision: 0.5, recall: 0.3921568691730499, f1score: 0.4395604435983825
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.5098039507865906, loss: 1.0139676332473755, precision: 0.5588235259056091, recall: 0.37254902720451355, f1score: 0.4470588278770446
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.6666666865348816, loss: 0.8350381851196289, precision: 0.6744186282157898, recall: 0.5686274766921997, f1score: 0.6170213015951577
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.5686274766921997, loss: 0.9497758746147156, precision: 0.6571428775787354, recall: 0.45098039507865906, f1score: 0.5348837297548791
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.5098039507865906, loss: 0.9647349119186401, precision: 0.6666666865348816, recall: 0.3921568691730499, f1score: 0.4938271710411511
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.6274510025978088, loss: 0.8703234791755676, precision: 0.8214285969734192, recall: 0.45098039507865906, f1score: 0.5822784898659679
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.5686274766921997, loss: 0.9395127892494202, precision: 0.6666666865348816, recall: 0.3529411852359772, f1score: 0.4615384737944462
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.5490196347236633, loss: 1.0274577140808105, precision: 0.6818181872367859, recall: 0.29411765933036804, f1score: 0.41095891707295606
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.5882353186607361, loss: 0.9389999508857727, precision: 0.6304348111152649, recall: 0.5686274766921997, f1score: 0.5979381713670554
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.6274510025978088, loss: 0.97519850730896, precision: 0.7058823704719543, recall: 0.47058823704719543, f1score: 0.5647058892250061