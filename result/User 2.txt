Model: linear-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.40781211853027344, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.48869219422340393, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: linear-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4356037676334381, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: linear-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.464934766292572, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.5156227350234985, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: linear-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.7979642152786255, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: linear-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.613104522228241, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: linear-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5218209028244019, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.9215686321258545, loss: 0.4359707534313202, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: linear-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.6693626642227173, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: linear-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.7670426964759827, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: linear-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5615093111991882, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.486675888299942, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: linear-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.7668795585632324, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: linear-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.48504334688186646, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: linear-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.42820867896080017, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5006790161132812, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.45234784483909607, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.49748313426971436, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.7774115800857544, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: relu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.8099561929702759, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: relu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5682627558708191, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.745521605014801, precision: 0.8199999928474426, recall: 0.8039215803146362, f1score: 0.8118811905728801
Model: relu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.5329076647758484, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: relu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.6839557886123657, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: relu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.9215686321258545, loss: 0.5145544409751892, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: relu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5057714581489563, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.5662264823913574, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.5386509895324707, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: relu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.6689740419387817, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: relu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.6383156180381775, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: relu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.4333389103412628, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.624197244644165, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.5576316714286804, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: relu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.590938150882721, precision: 0.8799999952316284, recall: 0.8627451062202454, f1score: 0.8712871305475794
Model: relu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.988458514213562, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: relu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.6992207169532776, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: relu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.7176592350006104, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: relu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.6299450993537903, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: relu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.9211744666099548, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.4684377610683441, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.8577008843421936, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.6476501822471619, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: tanh-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.6113976836204529, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.7390103936195374, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.5889593362808228, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.5057802200317383, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4251391589641571, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: tanh-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.42156028747558594, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.8159536719322205, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Mean accuracy: 0.9019607901573181, mean loss: 0.7243224382400513, mean precision: 0.9019607901573181, mean recall: 0.9019607901573181, mean f1score: 0.9019607901573181
Model: tanh-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.6494501233100891, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.6446028351783752, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.9664895534515381, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.7486684322357178, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.48881950974464417, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.7905575633049011, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.7402830123901367, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.6414393782615662, precision: 0.800000011920929, recall: 0.7843137383460999, f1score: 0.79207922031968
Model: tanh-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.6425508260726929, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.68133544921875, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.6329118609428406, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.5903799533843994, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.6510356664657593, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5479652285575867, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: sigmoid-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.6399679780006409, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: sigmoid-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 0.7830946445465088, precision: 0.7551020383834839, recall: 0.7254902124404907, f1score: 0.7400000073432921
Model: sigmoid-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.5633275508880615, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.4751223623752594, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: sigmoid-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.4870721697807312, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: sigmoid-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.574938952922821, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: sigmoid-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.5165604948997498, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.6639125347137451, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: sigmoid-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.8255167007446289, precision: 0.7647058963775635, recall: 0.7647058963775635, f1score: 0.7647058963775635
Model: sigmoid-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.5703498125076294, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: sigmoid-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.792151153087616, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: sigmoid-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.804671049118042, precision: 0.7400000095367432, recall: 0.7254902124404907, f1score: 0.7326732803449807
Model: sigmoid-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.5049417018890381, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.7675724625587463, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: sigmoid-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.7535133957862854, precision: 0.7111111283302307, recall: 0.6274510025978088, f1score: 0.6666666867677122
Model: sigmoid-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.8503813147544861, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: sigmoid-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.7741000056266785, precision: 0.7058823704719543, recall: 0.7058823704719543, f1score: 0.7058823704719543
Model: sigmoid-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7254902124404907, loss: 0.7436569929122925, precision: 0.7333333492279053, recall: 0.6470588445663452, f1score: 0.6875000188592821
Model: sigmoid-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.6073341369628906, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: sigmoid-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.4431433081626892, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: sigmoid-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.6067613363265991, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 0.6842342615127563, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: sigmoid-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.5290208458900452, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.4754980504512787, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5617696642875671, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.4328514635562897, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5138729810714722, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5004424452781677, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.45096471905708313, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.959447979927063, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.47658073902130127, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: leakyRelu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.5470263957977295, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.8394691348075867, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.6098570823669434, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.6184374094009399, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4979640245437622, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.6327613592147827, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: leakyRelu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.6170435547828674, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: leakyRelu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.4936334192752838, precision: 0.8571428656578064, recall: 0.8235294222831726, f1score: 0.8400000095605851
Model: leakyRelu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.6185547709465027, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.5181065201759338, precision: 0.8199999928474426, recall: 0.8039215803146362, f1score: 0.8118811905728801
Model: leakyRelu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.5932820439338684, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.6693168878555298, precision: 0.800000011920929, recall: 0.7843137383460999, f1score: 0.79207922031968
Model: leakyRelu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5526681542396545, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.6152675747871399, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: leakyRelu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.5504604578018188, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: leakyRelu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.59864342212677, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: linear-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.1535844802856445, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: linear-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.2569321393966675, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: linear-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 0.8607951998710632, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: linear-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 0.9143986701965332, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: linear-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9411764740943909, loss: 1.3863139152526855, precision: 0.9411764740943909, recall: 0.9411764740943909, f1score: 0.9411764740943909
Model: linear-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.3745015859603882, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: linear-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.5185987949371338, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 2.1301610469818115, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: linear-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.911185622215271, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: linear-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.5996603965759277, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: linear-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.815509557723999, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: linear-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 2.063556671142578, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: linear-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.5819830894470215, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: linear-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.1124626398086548, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: linear-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.147039532661438, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: linear-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 2.2146992683410645, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.3448989391326904, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.1143368482589722, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.090903401374817, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: relu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.4226741790771484, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.075667142868042, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.680404782295227, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.1134058237075806, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.0582362413406372, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.559364914894104, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.9089672565460205, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.1218140125274658, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.435711145401001, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.6993824243545532, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.9358395338058472, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.6518131494522095, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.7832670211791992, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.4260116815567017, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.8779776096343994, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.9027150869369507, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.248026967048645, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: relu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.4818774461746216, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.210770845413208, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: relu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.5191328525543213, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: relu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.5818227529525757, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 2.470005512237549, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.4135245084762573, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.9054032564163208, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.6206756830215454, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 0.9661998152732849, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: tanh-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.2382441759109497, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.0742230415344238, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: tanh-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.41185462474823, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.5311641693115234, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.856353998184204, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.9810470342636108, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 2.115816354751587, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.389974594116211, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 2.2096145153045654, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.9539397954940796, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 2.9055511951446533, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.4183083772659302, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.77309250831604, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 2.3226189613342285, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.6919686794281006, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 2.114835500717163, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.573415994644165, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.5119856595993042, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.8350567817687988, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: sigmoid-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.6847845315933228, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: sigmoid-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.7496455907821655, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: sigmoid-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.6394342184066772, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: sigmoid-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.8299378156661987, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: sigmoid-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.9767084121704102, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: sigmoid-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.2436562776565552, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: sigmoid-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.24702787399292, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: sigmoid-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.0843721628189087, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: sigmoid-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.1943250894546509, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: sigmoid-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.7598817348480225, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: sigmoid-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.8225771188735962, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: sigmoid-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.540248990058899, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: sigmoid-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.5406407117843628, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: sigmoid-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.822124719619751, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: sigmoid-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8235294222831726, loss: 1.7565033435821533, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: sigmoid-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.5179030895233154, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: sigmoid-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.266363501548767, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: sigmoid-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.3237515687942505, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: sigmoid-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.1215546131134033, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: sigmoid-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.061740517616272, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: sigmoid-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 2.017988681793213, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: sigmoid-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.3009341955184937, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: sigmoid-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.3844586610794067, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: sigmoid-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.2789146900177002, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: leakyRelu-linear-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.9508873224258423, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: leakyRelu-linear-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.0905256271362305, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-linear-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.5649911165237427, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: leakyRelu-linear-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.6621981859207153, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: leakyRelu-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.5591843128204346, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-relu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.9412180185317993, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-relu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.1649376153945923, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-relu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.0331556797027588, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: leakyRelu-relu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.392554759979248, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-tanh-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.574656367301941, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: leakyRelu-tanh-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.9211467504501343, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-tanh-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.7727326154708862, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-tanh-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.7522997856140137, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-tanh-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 2.328366994857788, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: leakyRelu-sigmoid-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.8163305521011353, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-sigmoid-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 2.30557918548584, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: leakyRelu-sigmoid-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.7522836923599243, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: leakyRelu-sigmoid-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.843137264251709, loss: 1.8597897291183472, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: leakyRelu-sigmoid-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 2.0981497764587402, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: leakyRelu-leakyRelu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.254030466079712, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-leakyRelu-relu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9215686321258545, loss: 1.0168957710266113, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: leakyRelu-leakyRelu-tanh-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.221321702003479, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-leakyRelu-sigmoid-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.3050031661987305, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: leakyRelu-leakyRelu-leakyRelu-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-Adam_Nodes-64. Accuracy: 0.9019607901573181, loss: 1.1630195379257202, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
REF: Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.7390103936195374, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.843137264251709, loss: 1.1613774299621582, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.9019607901573181, loss: 0.8965440392494202, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.8627451062202454, loss: 0.5004439949989319, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.9019607901573181, loss: 1.0189355611801147, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 1.3516169786453247, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 1.9558343887329102, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.7843137383460999, loss: 1.4753094911575317, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-32. Accuracy: 0.8039215803146362, loss: 1.1345551013946533, precision: 0.800000011920929, recall: 0.7843137383460999, f1score: 0.79207922031968
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.8384293913841248, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.9275123476982117, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 0.5595158934593201, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.0664808750152588, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 1.2108901739120483, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8823529481887817, loss: 1.8274595737457275, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.9725403189659119, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.8815699815750122, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8823529481887817, loss: 0.9145493507385254, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.9215686321258545, loss: 0.6410905718803406, precision: 0.9215686321258545, recall: 0.9215686321258545, f1score: 0.9215686321258545
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.9019607901573181, loss: 0.4641348421573639, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.843137264251709, loss: 0.9997679591178894, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.9019607901573181, loss: 0.8083706498146057, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.9019607901573181, loss: 0.8018338084220886, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.6458388566970825, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.01_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.8809025883674622, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.8823529481887817, loss: 0.7675755023956299, precision: 0.8799999952316284, recall: 0.8627451062202454, f1score: 0.8712871305475794
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.8627451062202454, loss: 0.489346981048584, precision: 0.8799999952316284, recall: 0.8627451062202454, f1score: 0.8712871305475794
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.433767169713974, precision: 0.8399999737739563, recall: 0.8235294222831726, f1score: 0.83168316082608
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.8823529481887817, loss: 0.6222589015960693, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.8627451062202454, loss: 0.6196538805961609, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.8039215803146362, loss: 0.47511544823646545, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.843137264251709, loss: 0.747356653213501, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.7508688569068909, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.623161256313324, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.5041799545288086, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.47244158387184143, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.8428118824958801, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.85164475440979, precision: 0.8600000143051147, recall: 0.843137264251709, f1score: 0.8514851602943794
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5451797246932983, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 1.7585278749465942, precision: 0.7599999904632568, recall: 0.7450980544090271, f1score: 0.7524752505981807
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-64. Accuracy: 0.8235294222831726, loss: 0.7511411309242249, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.8823529481887817, loss: 0.7584803104400635, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.9019607901573181, loss: 0.5925013422966003, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.8823529481887817, loss: 0.4719640016555786, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.8186936378479004, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.5288423895835876, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.9019607901573181, loss: 0.4784480929374695, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.843137264251709, loss: 0.5197204351425171, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.001_OPT-SGD_Nodes-128. Accuracy: 0.843137264251709, loss: 0.6587870121002197, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.7450980544090271, loss: 0.7403169274330139, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.686274528503418, loss: 0.6737446784973145, precision: 0.686274528503418, recall: 0.686274528503418, f1score: 0.686274528503418
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.6470588445663452, loss: 0.7913610935211182, precision: 0.6739130616188049, recall: 0.6078431606292725, f1score: 0.6391752788143541
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.7450980544090271, loss: 0.5918211936950684, precision: 0.7755101919174194, recall: 0.7450980544090271, f1score: 0.7600000020623204
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.686274528503418, loss: 0.7493796944618225, precision: 0.6938775777816772, recall: 0.6666666865348816, f1score: 0.6800000231862068
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.686274528503418, loss: 0.7697046399116516, precision: 0.6764705777168274, recall: 0.45098039507865906, f1score: 0.5411764693260193
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.7809709906578064, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-32. Accuracy: 0.8039215803146362, loss: 0.5426300168037415, precision: 0.8163265585899353, recall: 0.7843137383460999, f1score: 0.800000020122528
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.6171385049819946, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.7255343198776245, precision: 0.7799999713897705, recall: 0.7647058963775635, f1score: 0.7722772208513804
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.6470588445663452, loss: 0.76609867811203, precision: 0.6734693646430969, recall: 0.6470588445663452, f1score: 0.6599999998450272
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.8039215803146362, loss: 0.616223931312561, precision: 0.8199999928474426, recall: 0.8039215803146362, f1score: 0.8118811905728801
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.6668022871017456, precision: 0.7599999904632568, recall: 0.7450980544090271, f1score: 0.7524752505981807
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.686274528503418, loss: 0.752108633518219, precision: 0.6739130616188049, recall: 0.6078431606292725, f1score: 0.6391752788143541
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.7973456978797913, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 0.8255064487457275, precision: 0.7599999904632568, recall: 0.7450980544090271, f1score: 0.7524752505981807
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.5341634154319763, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.4876464009284973, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.7254902124404907, loss: 0.729723334312439, precision: 0.7254902124404907, recall: 0.7254902124404907, f1score: 0.7254902124404907
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.8039215803146362, loss: 0.6995932459831238, precision: 0.8039215803146362, recall: 0.8039215803146362, f1score: 0.8039215803146362
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.7647058963775635, loss: 0.5973219871520996, precision: 0.7599999904632568, recall: 0.7450980544090271, f1score: 0.7524752505981807
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.7254902124404907, loss: 0.7849894762039185, precision: 0.7200000286102295, recall: 0.7058823704719543, f1score: 0.7128713100917806
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.8039215803146362, loss: 0.6594387888908386, precision: 0.8367347121238708, recall: 0.8039215803146362, f1score: 0.8200000148415565
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0001_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 0.5021424293518066, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8823529481887817, loss: 0.49828457832336426, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.5939851403236389, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.7647058963775635, loss: 0.6692616939544678, precision: 0.7659574747085571, recall: 0.7058823704719543, f1score: 0.7346938998810404
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.5634214282035828, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.6076590418815613, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.7058823704719543, loss: 0.6991245746612549, precision: 0.7346938848495483, recall: 0.7058823704719543, f1score: 0.7200000126242637
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.7843137383460999, loss: 1.3950183391571045, precision: 0.800000011920929, recall: 0.7843137383460999, f1score: 0.79207922031968
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-32. Accuracy: 0.8235294222831726, loss: 0.9548227787017822, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.9019607901573181, loss: 0.4820170998573303, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7647058963775635, loss: 0.6149200201034546, precision: 0.7799999713897705, recall: 0.7647058963775635, f1score: 0.7722772208513804
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.6651246547698975, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.8627451062202454, loss: 0.5724374651908875, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.6591330766677856, precision: 0.7799999713897705, recall: 0.7647058963775635, f1score: 0.7722772208513804
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.7450980544090271, loss: 1.8458963632583618, precision: 0.7450980544090271, recall: 0.7450980544090271, f1score: 0.7450980544090271
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-64. Accuracy: 0.843137264251709, loss: 0.7402555346488953, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.8823529481887817, loss: 0.5274835228919983, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.8823529481887817, loss: 0.6388347744941711, precision: 0.8823529481887817, recall: 0.8823529481887817, f1score: 0.8823529481887817
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.7843137383460999, loss: 0.5516454577445984, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.8627451062202454, loss: 0.6632232069969177, precision: 0.8627451062202454, recall: 0.8627451062202454, f1score: 0.8627451062202454
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.9019607901573181, loss: 0.4116526246070862, precision: 0.9019607901573181, recall: 0.9019607901573181, f1score: 0.9019607901573181
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.843137264251709, loss: 0.5700335502624512, precision: 0.843137264251709, recall: 0.843137264251709, f1score: 0.843137264251709
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.8235294222831726, loss: 0.7263508439064026, precision: 0.8235294222831726, recall: 0.8235294222831726, f1score: 0.8235294222831726
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-0.0005_OPT-SGD_Nodes-128. Accuracy: 0.7843137383460999, loss: 0.7854255437850952, precision: 0.7843137383460999, recall: 0.7843137383460999, f1score: 0.7843137383460999
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.47058823704719543, loss: 0.9960505366325378, precision: 0.48148149251937866, recall: 0.2549019753932953, f1score: 0.33333334846962126
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.6666666865348816, loss: 0.8059331774711609, precision: 0.6818181872367859, recall: 0.5882353186607361, f1score: 0.6315789638397764
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.5882353186607361, loss: 0.8816365003585815, precision: 0.6000000238418579, recall: 0.23529411852359772, f1score: 0.3380281737022895
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.6078431606292725, loss: 0.869778573513031, precision: 0.6363636255264282, recall: 0.4117647111415863, f1score: 0.5000000005321842
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.4313725531101227, loss: 0.9771327376365662, precision: 0.4137931168079376, recall: 0.23529411852359772, f1score: 0.30000000422354783
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.6666666865348816, loss: 0.771860659122467, precision: 0.7250000238418579, recall: 0.5686274766921997, f1score: 0.6373626627275412
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.6274510025978088, loss: 0.9818657040596008, precision: 0.6904761791229248, recall: 0.5686274766921997, f1score: 0.6236559248119432
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-32. Accuracy: 0.5882353186607361, loss: 0.8256411552429199, precision: 0.6216216087341309, recall: 0.45098039507865906, f1score: 0.5227272701334238
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.9344251751899719, precision: 0.6818181872367859, recall: 0.5882353186607361, f1score: 0.6315789638397764
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.7058823704719543, loss: 0.784505307674408, precision: 0.7291666865348816, recall: 0.686274528503418, f1score: 0.7070707263368549
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.5882353186607361, loss: 0.8782215714454651, precision: 0.5666666626930237, recall: 0.3333333432674408, f1score: 0.41975309320601567
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.6078431606292725, loss: 0.8202943801879883, precision: 0.6363636255264282, recall: 0.5490196347236633, f1score: 0.5894736950549386
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.6274510025978088, loss: 0.772419273853302, precision: 0.6585366129875183, recall: 0.529411792755127, f1score: 0.58695654994993
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.5490196347236633, loss: 0.8377699851989746, precision: 0.5897436141967773, recall: 0.45098039507865906, f1score: 0.5111111221710839
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.7843137383460999, loss: 0.689518928527832, precision: 0.7872340679168701, recall: 0.7254902124404907, f1score: 0.7551020613465395
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-64. Accuracy: 0.5882353186607361, loss: 0.8407034873962402, precision: 0.574999988079071, recall: 0.45098039507865906, f1score: 0.505494502723368
Model: tanh-relu-linear-Yes_Drop0.1_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.7450980544090271, loss: 0.842681884765625, precision: 0.7551020383834839, recall: 0.7254902124404907, f1score: 0.7400000073432921
Model: tanh-relu-linear-Yes_Drop0.2_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.7058823704719543, loss: 0.7261886596679688, precision: 0.7446808218955994, recall: 0.686274528503418, f1score: 0.7142857109964109
Model: tanh-relu-linear-Yes_Drop0.5_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.7254902124404907, loss: 0.8393705487251282, precision: 0.7692307829856873, recall: 0.5882353186607361, f1score: 0.6666666875945196
Model: tanh-relu-linear-Yes_Drop0.1_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.6274510025978088, loss: 0.7725500464439392, precision: 0.6666666865348816, recall: 0.5882353186607361, f1score: 0.6250000225845724
Model: tanh-relu-linear-Yes_Drop0.2_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.6078431606292725, loss: 0.7405800223350525, precision: 0.6304348111152649, recall: 0.5686274766921997, f1score: 0.5979381713670554
Model: tanh-relu-linear-Yes_Drop0.5_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.6470588445663452, loss: 0.7922384142875671, precision: 0.6428571343421936, recall: 0.529411792755127, f1score: 0.5806451746874117
Model: tanh-relu-linear-No_Drop_Yes_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.7647058963775635, loss: 0.6929115653038025, precision: 0.7916666865348816, recall: 0.7450980544090271, f1score: 0.7676767850819808
Model: tanh-relu-linear-No_Drop_No_batch-softmax_LR-1e-05_OPT-SGD_Nodes-128. Accuracy: 0.686274528503418, loss: 0.7472788691520691, precision: 0.6875, recall: 0.6470588445663452, f1score: 0.6666666778322748